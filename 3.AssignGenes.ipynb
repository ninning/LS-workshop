{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33864d1e-b381-473c-988c-9924f4479635",
   "metadata": {},
   "source": [
    "### featureCounts\n",
    "The next step will use the featurecounts package to assign each read to a \"feature\" in the GTF file.  \n",
    "These features run the spectrum of \"exons\", \"gene\", \"UTR\", \"start_codon\", \"stop_codon\" etc...  \n",
    "If you look through typically the third column of your GTF file, you can see all the different types of features.  \n",
    "\n",
    "For the purposes of the LS pipeline, we will use the default featurecounts setting of mapping to \"exons\".  \n",
    "Typically for Diff Expression analysis, the exons are what you want to use.  \n",
    "There are some papers that do some DEA with introns and other features.  \n",
    "Light-seq can capture both exons and introns, so the type of analysis you want to do is really up to you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6496623-c389-4afe-b889-3c3848043d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Version 2.0.1\n",
      "\n",
      "Usage: featureCounts [options] -a <annotation_file> -o <output_file> input_file1 [input_file2] ... \n",
      "\n",
      "## Mandatory arguments:\n",
      "\n",
      "  -a <string>         Name of an annotation file. GTF/GFF format by default. See\n",
      "                      -F option for more format information. Inbuilt annotations\n",
      "                      (SAF format) is available in 'annotation' directory of the\n",
      "                      package. Gzipped file is also accepted.\n",
      "\n",
      "  -o <string>         Name of output file including read counts. A separate file\n",
      "                      including summary statistics of counting results is also\n",
      "                      included in the output ('<string>.summary'). Both files\n",
      "                      are in tab delimited format.\n",
      "\n",
      "  input_file1 [input_file2] ...   A list of SAM or BAM format files. They can be\n",
      "                      either name or location sorted. If no files provided,\n",
      "                      <stdin> input is expected. Location-sorted paired-end reads\n",
      "                      are automatically sorted by read names.\n",
      "\n",
      "## Optional arguments:\n",
      "# Annotation\n",
      "\n",
      "  -F <string>         Specify format of the provided annotation file. Acceptable\n",
      "                      formats include 'GTF' (or compatible GFF format) and\n",
      "                      'SAF'. 'GTF' by default.  For SAF format, please refer to\n",
      "                      Users Guide.\n",
      "\n",
      "  -t <string>         Specify feature type(s) in a GTF annotation. If multiple\n",
      "                      types are provided, they should be separated by ',' with\n",
      "                      no space in between. 'exon' by default. Rows in the\n",
      "                      annotation with a matched feature will be extracted and\n",
      "                      used for read mapping. \n",
      "\n",
      "  -g <string>         Specify attribute type in GTF annotation. 'gene_id' by \n",
      "                      default. Meta-features used for read counting will be \n",
      "                      extracted from annotation using the provided value.\n",
      "\n",
      "  --extraAttributes   Extract extra attribute types from the provided GTF\n",
      "                      annotation and include them in the counting output. These\n",
      "                      attribute types will not be used to group features. If\n",
      "                      more than one attribute type is provided they should be\n",
      "                      separated by comma.\n",
      "\n",
      "  -A <string>         Provide a chromosome name alias file to match chr names in\n",
      "                      annotation with those in the reads. This should be a two-\n",
      "                      column comma-delimited text file. Its first column should\n",
      "                      include chr names in the annotation and its second column\n",
      "                      should include chr names in the reads. Chr names are case\n",
      "                      sensitive. No column header should be included in the\n",
      "                      file.\n",
      "\n",
      "# Level of summarization\n",
      "\n",
      "  -f                  Perform read counting at feature level (eg. counting \n",
      "                      reads for exons rather than genes).\n",
      "\n",
      "# Overlap between reads and features\n",
      "\n",
      "  -O                  Assign reads to all their overlapping meta-features (or \n",
      "                      features if -f is specified).\n",
      "\n",
      "  --minOverlap <int>  Minimum number of overlapping bases in a read that is\n",
      "                      required for read assignment. 1 by default. Number of\n",
      "                      overlapping bases is counted from both reads if paired\n",
      "                      end. If a negative value is provided, then a gap of up\n",
      "                      to specified size will be allowed between read and the\n",
      "                      feature that the read is assigned to.\n",
      "\n",
      "  --fracOverlap <float> Minimum fraction of overlapping bases in a read that is\n",
      "                      required for read assignment. Value should be within range\n",
      "                      [0,1]. 0 by default. Number of overlapping bases is\n",
      "                      counted from both reads if paired end. Both this option\n",
      "                      and '--minOverlap' option need to be satisfied for read\n",
      "                      assignment.\n",
      "\n",
      "  --fracOverlapFeature <float> Minimum fraction of overlapping bases in a\n",
      "                      feature that is required for read assignment. Value\n",
      "                      should be within range [0,1]. 0 by default.\n",
      "\n",
      "  --largestOverlap    Assign reads to a meta-feature/feature that has the \n",
      "                      largest number of overlapping bases.\n",
      "\n",
      "  --nonOverlap <int>  Maximum number of non-overlapping bases in a read (or a\n",
      "                      read pair) that is allowed when being assigned to a\n",
      "                      feature. No limit is set by default.\n",
      "\n",
      "  --nonOverlapFeature <int> Maximum number of non-overlapping bases in a feature\n",
      "                      that is allowed in read assignment. No limit is set by\n",
      "                      default.\n",
      "\n",
      "  --readExtension5 <int> Reads are extended upstream by <int> bases from their\n",
      "                      5' end.\n",
      "\n",
      "  --readExtension3 <int> Reads are extended upstream by <int> bases from their\n",
      "                      3' end.\n",
      "\n",
      "  --read2pos <5:3>    Reduce reads to their 5' most base or 3' most base. Read\n",
      "                      counting is then performed based on the single base the \n",
      "                      read is reduced to.\n",
      "\n",
      "# Multi-mapping reads\n",
      "\n",
      "  -M                  Multi-mapping reads will also be counted. For a multi-\n",
      "                      mapping read, all its reported alignments will be \n",
      "                      counted. The 'NH' tag in BAM/SAM input is used to detect \n",
      "                      multi-mapping reads.\n",
      "\n",
      "# Fractional counting\n",
      "\n",
      "  --fraction          Assign fractional counts to features. This option must\n",
      "                      be used together with '-M' or '-O' or both. When '-M' is\n",
      "                      specified, each reported alignment from a multi-mapping\n",
      "                      read (identified via 'NH' tag) will carry a fractional\n",
      "                      count of 1/x, instead of 1 (one), where x is the total\n",
      "                      number of alignments reported for the same read. When '-O'\n",
      "                      is specified, each overlapping feature will receive a\n",
      "                      fractional count of 1/y, where y is the total number of\n",
      "                      features overlapping with the read. When both '-M' and\n",
      "                      '-O' are specified, each alignment will carry a fractional\n",
      "                      count of 1/(x*y).\n",
      "\n",
      "# Read filtering\n",
      "\n",
      "  -Q <int>            The minimum mapping quality score a read must satisfy in\n",
      "                      order to be counted. For paired-end reads, at least one\n",
      "                      end should satisfy this criteria. 0 by default.\n",
      "\n",
      "  --splitOnly         Count split alignments only (ie. alignments with CIGAR\n",
      "                      string containing 'N'). An example of split alignments is\n",
      "                      exon-spanning reads in RNA-seq data.\n",
      "\n",
      "  --nonSplitOnly      If specified, only non-split alignments (CIGAR strings do\n",
      "                      not contain letter 'N') will be counted. All the other\n",
      "                      alignments will be ignored.\n",
      "\n",
      "  --primary           Count primary alignments only. Primary alignments are \n",
      "                      identified using bit 0x100 in SAM/BAM FLAG field.\n",
      "\n",
      "  --ignoreDup         Ignore duplicate reads in read counting. Duplicate reads \n",
      "                      are identified using bit Ox400 in BAM/SAM FLAG field. The \n",
      "                      whole read pair is ignored if one of the reads is a \n",
      "                      duplicate read for paired end data.\n",
      "\n",
      "# Strandness\n",
      "\n",
      "  -s <int or string>  Perform strand-specific read counting. A single integer\n",
      "                      value (applied to all input files) or a string of comma-\n",
      "                      separated values (applied to each corresponding input\n",
      "                      file) should be provided. Possible values include:\n",
      "                      0 (unstranded), 1 (stranded) and 2 (reversely stranded).\n",
      "                      Default value is 0 (ie. unstranded read counting carried\n",
      "                      out for all input files).\n",
      "\n",
      "# Exon-exon junctions\n",
      "\n",
      "  -J                  Count number of reads supporting each exon-exon junction.\n",
      "                      Junctions were identified from those exon-spanning reads\n",
      "                      in the input (containing 'N' in CIGAR string). Counting\n",
      "                      results are saved to a file named '<output_file>.jcounts'\n",
      "\n",
      "  -G <string>         Provide the name of a FASTA-format file that contains the\n",
      "                      reference sequences used in read mapping that produced the\n",
      "                      provided SAM/BAM files. This optional argument can be used\n",
      "                      with '-J' option to improve read counting for junctions.\n",
      "\n",
      "# Parameters specific to paired end reads\n",
      "\n",
      "  -p                  If specified, fragments (or templates) will be counted\n",
      "                      instead of reads. This option is only applicable for\n",
      "                      paired-end reads; single-end reads are always counted as\n",
      "                      reads.\n",
      "\n",
      "  -B                  Only count read pairs that have both ends aligned.\n",
      "\n",
      "  -P                  Check validity of paired-end distance when counting read \n",
      "                      pairs. Use -d and -D to set thresholds.\n",
      "\n",
      "  -d <int>            Minimum fragment/template length, 50 by default.\n",
      "\n",
      "  -D <int>            Maximum fragment/template length, 600 by default.\n",
      "\n",
      "  -C                  Do not count read pairs that have their two ends mapping \n",
      "                      to different chromosomes or mapping to same chromosome \n",
      "                      but on different strands.\n",
      "\n",
      "  --donotsort         Do not sort reads in BAM/SAM input. Note that reads from \n",
      "                      the same pair are required to be located next to each \n",
      "                      other in the input.\n",
      "\n",
      "# Number of CPU threads\n",
      "\n",
      "  -T <int>            Number of the threads. 1 by default.\n",
      "\n",
      "# Read groups\n",
      "\n",
      "  --byReadGroup       Assign reads by read group. \"RG\" tag is required to be\n",
      "                      present in the input BAM/SAM files.\n",
      "                      \n",
      "\n",
      "# Long reads\n",
      "\n",
      "  -L                  Count long reads such as Nanopore and PacBio reads. Long\n",
      "                      read counting can only run in one thread and only reads\n",
      "                      (not read-pairs) can be counted. There is no limitation on\n",
      "                      the number of 'M' operations allowed in a CIGAR string in\n",
      "                      long read counting.\n",
      "\n",
      "# Assignment results for each read\n",
      "\n",
      "  -R <format>         Output detailed assignment results for each read or read-\n",
      "                      pair. Results are saved to a file that is in one of the\n",
      "                      following formats: CORE, SAM and BAM. See Users Guide for\n",
      "                      more info about these formats.\n",
      "\n",
      "  --Rpath <string>    Specify a directory to save the detailed assignment\n",
      "                      results. If unspecified, the directory where counting\n",
      "                      results are saved is used.\n",
      "\n",
      "# Miscellaneous\n",
      "\n",
      "  --tmpDir <string>   Directory under which intermediate files are saved (later\n",
      "                      removed). By default, intermediate files will be saved to\n",
      "                      the directory specified in '-o' argument.\n",
      "\n",
      "  --maxMOp <int>      Maximum number of 'M' operations allowed in a CIGAR\n",
      "                      string. 10 by default. Both 'X' and '=' are treated as 'M'\n",
      "                      and adjacent 'M' operations are merged in the CIGAR\n",
      "                      string.\n",
      "\n",
      "  --verbose           Output verbose information for debugging, such as un-\n",
      "                      matched chromosome/contig names.\n",
      "\n",
      "  -v                  Output version of the program.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lets take a look at the options in featurecounts\n",
    "!featurecounts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b662eac-3102-4c17-8b72-b091f748810b",
   "metadata": {},
   "source": [
    "### Mandatory requirements\n",
    "We can see from the options that we have three mandatory arguments.  \n",
    "We need to provide the path to the GTF file, a path for the summary files and a path to the BAM file of interest.\n",
    "For mouse and human GTF files. We get our GTF/GFF3 file from genecode, the comprehensive Chr annotation:  \n",
    "https://www.gencodegenes.org/mouse/\n",
    "\n",
    "And for the majority of the analysis, we used the vM27 version.  \n",
    "Ideally you should use the same GTF file for this part of the pipeline that you used to build the index with STAR aligner.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3aa5552d-b01b-4b69-9bae-e8699e7eb109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       \u001b[44;37m ========== \u001b[0m\u001b[36m    _____ _    _ ____  _____  ______          _____  \n",
      "       \u001b[44;37m =====      \u001b[0m\u001b[36m   / ____| |  | |  _ \\|  __ \\|  ____|   /\\   |  __ \\ \n",
      "       \u001b[44;37m   =====    \u001b[0m\u001b[36m  | (___ | |  | | |_) | |__) | |__     /  \\  | |  | |\n",
      "       \u001b[44;37m     ====   \u001b[0m\u001b[36m   \\___ \\| |  | |  _ <|  _  /|  __|   / /\\ \\ | |  | |\n",
      "       \u001b[44;37m       ==== \u001b[0m\u001b[36m   ____) | |__| | |_) | | \\ \\| |____ / ____ \\| |__| |\n",
      "       \u001b[44;37m ========== \u001b[0m\u001b[36m  |_____/ \\____/|____/|_|  \\_\\______/_/    \\_\\_____/\u001b[0m\n",
      "\t  v2.0.1\n",
      "\n",
      "//==========================\u001b[36m featureCounts setting \u001b[0m===========================\\\\\n",
      "||  \u001b[0m                                                                          ||\n",
      "||             Input files : \u001b[36m1 BAM file  \u001b[0m \u001b[0m                                    ||\n",
      "||                           \u001b[32mo\u001b[36m TLS23A_R1_MouseAligned.sortedByCoord.out.bam\u001b[0m \u001b[0m  ||\n",
      "||  \u001b[0m                                                                          ||\n",
      "||             Output file : \u001b[36mLS23A_GeneAssigned\u001b[0m \u001b[0m                              ||\n",
      "||                 Summary : \u001b[36mLS23A_GeneAssigned.summary\u001b[0m \u001b[0m                      ||\n",
      "||              Annotation : \u001b[36mgencode.vM27.annotation.gff3 (GTF)\u001b[0m \u001b[0m              ||\n",
      "||      Dir for temp files : \u001b[36moutFiles\u001b[0m \u001b[0m                                        ||\n",
      "||      Assignment details : \u001b[36m<input_file>.featureCounts.bam\u001b[0m \u001b[0m                  ||\n",
      "||                      (Note that files are saved to the output directory) \u001b[0m  ||\n",
      "||  \u001b[0m                                                                          ||\n",
      "||  \u001b[0m                                                                          ||\n",
      "||                 Threads : \u001b[36m1\u001b[0m \u001b[0m                                               ||\n",
      "||                   Level : \u001b[36mmeta-feature level\u001b[0m \u001b[0m                              ||\n",
      "||              Paired-end : \u001b[36mno\u001b[0m \u001b[0m                                              ||\n",
      "||      Multimapping reads : \u001b[36mnot counted\u001b[0m \u001b[0m                                     ||\n",
      "|| Multi-overlapping reads : \u001b[36mnot counted\u001b[0m \u001b[0m                                     ||\n",
      "||   Min overlapping bases : \u001b[36m1\u001b[0m \u001b[0m                                               ||\n",
      "||  \u001b[0m                                                                          ||\n",
      "\\\\============================================================================//\n",
      "\n",
      "//=================================\u001b[36m Running \u001b[0m==================================\\\\\n",
      "||  \u001b[0m                                                                          ||\n",
      "|| Load annotation file gencode.vM27.annotation.gff3 \u001b[0m... \u001b[0m                     ||\n",
      "||    Features : \u001b[36m841952\u001b[0m \u001b[0m                                                      ||\n",
      "||    Meta-features : \u001b[36m55359\u001b[0m \u001b[0m                                                  ||\n",
      "||    Chromosomes/contigs : \u001b[36m22\u001b[0m \u001b[0m                                               ||\n",
      "||  \u001b[0m                                                                          ||\n",
      "|| Process BAM file TLS23A_R1_MouseAligned.sortedByCoord.out.bam... \u001b[0m          ||\n",
      "||    Single-end reads are included. \u001b[0m                                         ||\n",
      "||    Total alignments : \u001b[36m1731739\u001b[0m \u001b[0m                                             ||\n",
      "||    Successfully assigned alignments : \u001b[36m685294 (39.6%)\u001b[0m \u001b[0m                      ||\n",
      "||    Running time : \u001b[36m0.08 minutes\u001b[0m \u001b[0m                                            ||\n",
      "||  \u001b[0m                                                                          ||\n",
      "|| Write the final count table. \u001b[0m                                              ||\n",
      "|| Write the read assignment summary. \u001b[0m                                        ||\n",
      "||  \u001b[0m                                                                          ||\n",
      "|| Summary of counting results can be found in file \"outFiles/LS23A_GeneAssi \u001b[0m ||\n",
      "|| gned.summary\" \u001b[0m                                                             ||\n",
      "||  \u001b[0m                                                                          ||\n",
      "\\\\============================================================================//\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now lets run the featurecounts package on the mapped .bam file from STAR aligner\n",
    "!featurecounts -a gtf_file/gencode.vM27.annotation.gff3 -o outFiles/LS23A_GeneAssigned -R BAM outFiles/TLS23A_R1_MouseAligned.sortedByCoord.out.bam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44803a28-7670-450d-b3b6-ccfb1bedaf00",
   "metadata": {},
   "source": [
    "### Output\n",
    "You should now have another slightly larger BAM file with a \"featureCounts\" tag attached to it.  \n",
    "Note with the default options, we also do not consider multimapping reads.  \n",
    "However we filtered out multimapping reads at the STAR aligner mapping stage so setting this option to True will not do anything for use at this stage.  \n",
    "\n",
    "Lets take a look at the two BAM files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5a672a6-9a4a-4ddc-a943-cff93d1c7e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the pysam module\n",
    "import pysam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d36f64-d274-483d-9dab-6441307567f0",
   "metadata": {},
   "source": [
    "### Pysam\n",
    "Pysam is the main module we use to read BAM files.  \n",
    "It has quite an extensive documentation as well and is worth reading.  \n",
    "https://pysam.readthedocs.io/en/latest/api.html#api\n",
    "\n",
    "The main thing to understand is what it returns when you read a BAM file.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "645ac247-afb7-4f33-8a9e-2591e6a7c4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[E::idx_find_and_load] Could not retrieve index file for 'outFiles/TLS23A_R1_MouseAligned.sortedByCoord.out.bam'\n"
     ]
    }
   ],
   "source": [
    "# Read the a BAM file, from the STAR aligner\n",
    "samfile = pysam.AlignmentFile(\n",
    "    \"outFiles/TLS23A_R1_MouseAligned.sortedByCoord.out.bam\", \"rb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1f0af7-efbe-4b35-958d-31b6523e5012",
   "metadata": {},
   "source": [
    "#### Note\n",
    "You will typically get an error saying there is no index file.  \n",
    "If you want to generate an index file to remove that error, you can run `samtools index`.  \n",
    "However we do not actually need an index file to iterate over the samfile which is what we are mainly going to do.  \n",
    "As stated here http://www.htslib.org/doc/samtools-index.html, an index is only needed if you want to retrieve a specific region, like all chr1 maps for example. \n",
    "\n",
    "As an example this is mentioned in the `fetch` function for pysam.\n",
    "```\n",
    "fetch(self, contig=None, start=None, stop=None, region=None, tid=None, until_eof=False, multiple_iterators=False, reference=None, end=None)\n",
    "fetch reads aligned in a region.\n",
    "\n",
    "If there is no index, use until_eof=True.\n",
    "\n",
    "```\n",
    "So you would use the `until_eof` flag for BAM files without an index.\n",
    "\n",
    "There are some other useful pysam functions like `mapped` and `get_index_statistics` that do require an index but will not be discussed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34f84485-49e5-4efb-960e-601c7a86e24e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pysam.libcalignmentfile.AlignmentFile at 0x104fe3af0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is the read samfile\n",
    "samfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06034c44-6030-4351-a765-ff49d1e235d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pysam.libcalignedsegment.AlignedSegment at 0x10512eb40>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that this is a python Iterator object, meaning you call it with the \"next\" command.\n",
    "# Everytime you iterate through this with \"next\", it will return an \"alignmedsegment\"\n",
    "next(samfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b91bd114-b94d-4318-b6c5-8deadc79fbb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M01675:146:000000000-JNRMM:1:1112:24140:17066_AGGGTA_GGTTGTGGAGGG\t0\t#0\t3270322\t255\t40M\t*\t0\t0\tTTGGAATATGTATATCTATATATCTCTATATATATTTACA\tarray('B', [38, 38, 37, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 37, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38])\t[('NH', 1), ('HI', 1), ('AS', 39), ('nM', 0)]\n"
     ]
    }
   ],
   "source": [
    "# We can take a look at the details here\n",
    "print(next(samfile))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c78e12-1412-4853-b146-088f537f8ce8",
   "metadata": {},
   "source": [
    "### Reading the BAM file\n",
    "The output here should be in the standard SAM/BAM format.  \n",
    "You have lines correspending to the instrument and cluster info, the alignment scores, the sequence, and the tags.  \n",
    "All of our tags for \"NH\" which is number of hits should be 1 since we are only doing unique "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67809cf1-39af-45e7-9210-b2d8b9a2bcbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TGATATATCTTCACGTTGCCTGCACACACCTTATTTCTGA'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#If you want to call a specific part of the AlignedSegment like so\n",
    "next(samfile).seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ab36326-f4c4-4f8a-a126-34e2ad29f01e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NH', 1), ('HI', 1), ('AS', 39), ('nM', 0)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(samfile).tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4b6c1d9-5d6f-4444-a044-7d5e21bf0ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[E::idx_find_and_load] Could not retrieve index file for 'outFiles/TLS23A_R1_MouseAligned.sortedByCoord.out.bam'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1731739 reads\n"
     ]
    }
   ],
   "source": [
    "# Remember once you call a part of the iterator with \"next\", you cant go back!  \n",
    "# Lets load it again and count the number of reads in the file.\n",
    "samfile = pysam.AlignmentFile(\n",
    "    \"outFiles/TLS23A_R1_MouseAligned.sortedByCoord.out.bam\", \"rb\"\n",
    ")\n",
    "samcount = 0\n",
    "for read in samfile:\n",
    "    samcount+=1\n",
    "    \n",
    "print(\"%s reads\" % str(samcount))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a01270-0e8a-489b-b31e-956d7a97f34e",
   "metadata": {},
   "source": [
    "If you go back to the featurecounts output, this should be exactly the same amount for Total alignments.  \n",
    "And if you try to iterate through the samfile again you will get an error since ive already gone through the whole thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e79d7ed2-ad0c-414d-8197-9f392fb41c11",
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sq/qy7gh_jj1lgfdyh2wf4vt8p00000gn/T/ipykernel_55590/3504144675.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mpysam/libcalignmentfile.pyx\u001b[0m in \u001b[0;36mpysam.libcalignmentfile.AlignmentFile.__next__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "next(samfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a459b94-47d9-411f-a2eb-393808547e6d",
   "metadata": {},
   "source": [
    "### Featurecounts BAM file\n",
    "Featurecounts will add an extra \"tag\" to the bam file indicating which gene the map got assigned to, lets compare and contrast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3912a838-e80b-4933-9df8-2441795f7d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[E::idx_find_and_load] Could not retrieve index file for 'outFiles/TLS23A_R1_MouseAligned.sortedByCoord.out.bam'\n",
      "[E::idx_find_and_load] Could not retrieve index file for 'outFiles/TLS23A_R1_MouseAligned.sortedByCoord.out.bam.featureCounts.bam'\n"
     ]
    }
   ],
   "source": [
    "samfile = pysam.AlignmentFile(\n",
    "    \"outFiles/TLS23A_R1_MouseAligned.sortedByCoord.out.bam\", \"rb\"\n",
    ")\n",
    "samfile_fc = pysam.AlignmentFile(\n",
    "    \"outFiles/TLS23A_R1_MouseAligned.sortedByCoord.out.bam.featureCounts.bam\", \"rb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4fd834c-27d1-4be7-91bc-e29c80d22165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M01675:146:000000000-JNRMM:1:1113:14523:9922_AGGGTA_GGGGGGGGAGTG\t0\t#0\t3204065\t255\t2S38M\t*\t0\t0\tATTTGAACTCAAGACCTTTGGAAGAGCAGTCAATGCTCTT\tarray('B', [38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38])\t[('NH', 1), ('HI', 1), ('AS', 37), ('nM', 0)]\n"
     ]
    }
   ],
   "source": [
    "# Samfile read\n",
    "print(next(samfile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a3aa081-442a-4830-bc33-0be49cb04a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M01675:146:000000000-JNRMM:1:1113:14523:9922_AGGGTA_GGGGGGGGAGTG\t0\t#0\t3204065\t255\t2S38M\t*\t0\t0\tATTTGAACTCAAGACCTTTGGAAGAGCAGTCAATGCTCTT\tarray('B', [38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38])\t[('NH', 1), ('HI', 1), ('AS', 37), ('nM', 0), ('XS', 'Unassigned_NoFeatures')]\n"
     ]
    }
   ],
   "source": [
    "# Featurecounts read\n",
    "print(next(samfile_fc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5370150-323e-4575-946b-08f276bc322b",
   "metadata": {},
   "source": [
    "The extra tag here is the \"XS\" tag, in this case, this read was not assigned and thus was given the tag \"unassigned_nofeatures\".  \n",
    "Note that this does not mean that the read doesnt exist in the GTF file.  \n",
    "Since we are using the \"exon\" mapping option, this read could be something else, an intron for example.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2df499e1-59c0-4f4e-bf2d-301e83e6d73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets try to find a read that did get assigned\n",
    "for read in samfile_fc:\n",
    "    if read.get_tag(\"XS\") == \"Assigned\":\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51460cf2-11e4-40c7-9fc1-a414b4dd3f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M01675:146:000000000-JNRMM:1:1108:12080:20749_AGGGTA_TGGGGTGGAGAA\t0\t#0\t3276206\t255\t40M\t*\t0\t0\tCCTATATGCTAGTACAGATCTTCTGTCCTGGTACTCATTA\tarray('B', [38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38])\t[('NH', 1), ('HI', 1), ('AS', 39), ('nM', 0), ('XS', 'Assigned'), ('XN', 1), ('XT', 'ENSMUSG00000051951.6')]\n"
     ]
    }
   ],
   "source": [
    "print(read)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a244d535-ffa7-4ea7-bfff-45565a2210ce",
   "metadata": {},
   "source": [
    "#### We see that an assigned read has the tag \"XS\" \"Assigned\" and \"XT\", which corresponds to the ENSEMBL Gene ID that it was assigned to.\n",
    "If you want to get the read tag for the gene and the sequence. You use the `.seq` and `.get_tag` and other functions.  \n",
    "These are documented in the pysam documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "453a5190-1d72-4cd6-928f-9932d07fa53d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CCTATATGCTAGTACAGATCTTCTGTCCTGGTACTCATTA'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read.seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b23b95b4-9177-428b-9f93-beac9db076f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ENSMUSG00000051951.6'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read.get_tag('XT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26a0e97a-af7b-4079-8235-f611fbe0ff6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read.mapping_quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "661ee245-c823-46e6-b2d5-4d73e1c27d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read.qual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74d6ce2d-b0b2-48ab-8352-15454030038e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'M01675:146:000000000-JNRMM:1:1108:12080:20749_AGGGTA_TGGGGTGGAGAA'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read.qname"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dab32a8-98bb-4d71-b7e2-359a1009ba1d",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Once you have familiarized yourself pysams functionality, you are pretty much halfway done with parsing out the sequencing data for your purposes.  \n",
    "For example checking for multimapped reads means you look at the \"NH\" tag.  \n",
    "Filtering out reads with bad alignment scores etc...  \n",
    "Of course there should already be packages out there that do most of this stuff.  \n",
    "For example featurecounts can also do paired end read analysis, you just need to set it as the option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb71c3a6-fd0a-4458-b3c7-858be50911a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSEnv",
   "language": "python",
   "name": "lsenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
